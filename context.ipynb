{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8acb724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in d:\\anaconda\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in d:\\anaconda\\lib\\site-packages (from pypdf) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2994cea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in d:\\anaconda\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.0 in d:\\anaconda\\lib\\site-packages (from langchain-google-genai) (0.5.2)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.27 in d:\\anaconda\\lib\\site-packages (from langchain-google-genai) (0.1.45)\n",
      "Requirement already satisfied: google-api-python-client in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.127.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.6.2)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.64.1)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.21.12)\n",
      "Requirement already satisfied: pydantic in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.7.1)\n",
      "Requirement already satisfied: google-api-core in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.18.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\anaconda\\lib\\site-packages (from google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.23.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (8.2.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (0.1.50)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in d:\\anaconda\\lib\\site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.18.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.63.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in d:\\anaconda\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\anaconda\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\anaconda\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.2.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.6)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.62.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\anaconda\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2247193",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in d:\\anaconda\\lib\\site-packages (0.0.34)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\anaconda\\lib\\site-packages (from langchain_community) (1.4.39)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.45 in d:\\anaconda\\lib\\site-packages (from langchain_community) (0.1.45)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda\\lib\\site-packages (from langchain_community) (6.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\\anaconda\\lib\\site-packages (from langchain_community) (0.1.50)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\anaconda\\lib\\site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\anaconda\\lib\\site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anaconda\\lib\\site-packages (from langchain_community) (2.28.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\anaconda\\lib\\site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\anaconda\\lib\\site-packages (from langchain_community) (1.23.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anaconda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\anaconda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (2.7.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain_community) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain_community) (2.1)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain_community) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain_community) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc599e2b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.28 in d:\\anaconda\\lib\\site-packages (from langchain-text-splitters) (0.1.45)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (6.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (23.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (0.1.50)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.18.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b66767d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "     -------------------------------------- 526.8/526.8 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity>=8.2.3 in d:\\anaconda\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\anaconda\\lib\\site-packages (from chromadb) (3.10.1)\n",
      "Requirement already satisfied: requests>=2.28 in d:\\anaconda\\lib\\site-packages (from chromadb) (2.28.1)\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\anaconda\\lib\\site-packages (from chromadb) (2.7.1)\n",
      "Collecting fastapi>=0.95.2\n",
      "  Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
      "     ---------------------------------------- 91.9/91.9 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in d:\\anaconda\\lib\\site-packages (from chromadb) (1.23.5)\n",
      "Collecting overrides>=7.3.1\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\anaconda\\lib\\site-packages (from chromadb) (1.62.2)\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in d:\\anaconda\\lib\\site-packages (from chromadb) (6.0)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.1/60.1 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting mmh3>=4.0.1\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-win_amd64.whl (31 kB)\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-win_amd64.whl (158 kB)\n",
      "     -------------------------------------- 158.3/158.3 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "     -------------------------------------- 106.1/106.1 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\anaconda\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 5.4 MB/s eta 0:00:00\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Collecting chroma-hnswlib==0.7.3\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-win_amd64.whl (150 kB)\n",
      "     -------------------------------------- 150.6/150.6 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.65.0\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.8/60.8 kB ? eta 0:00:00\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 67.3/67.3 kB ? eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.17.3-cp310-cp310-win_amd64.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 6.3 MB/s eta 0:00:00\n",
      "Collecting posthog>=2.4.0\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.3/41.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in d:\\anaconda\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: tomli>=1.1.0 in d:\\anaconda\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting starlette<0.38.0,>=0.37.2\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.9/71.9 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3>=1.24.2 in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.26.14)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\anaconda\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.21.12)\n",
      "Requirement already satisfied: flatbuffers in d:\\anaconda\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting deprecated>=1.2.6\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting importlib-metadata<=7.0,>=6.0\n",
      "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.24.0\n",
      "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.8/50.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\anaconda\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Collecting opentelemetry-util-http==0.45b0\n",
      "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0\n",
      "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in d:\\anaconda\\lib\\site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.6.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in d:\\anaconda\\lib\\site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in d:\\anaconda\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "     ------------------------------------- 388.9/388.9 kB 12.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\anaconda\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "     ------------------------------------- 240.7/240.7 kB 14.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h11>=0.8 in d:\\anaconda\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.21.0-cp310-none-win_amd64.whl (279 kB)\n",
      "     -------------------------------------- 279.7/279.7 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-12.0-cp310-cp310-win_amd64.whl (124 kB)\n",
      "     ---------------------------------------- 125.0/125.0 kB ? eta 0:00:00\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp310-cp310-win_amd64.whl (58 kB)\n",
      "     ---------------------------------------- 58.2/58.2 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "     -------------------------------------- 172.0/172.0 kB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 kB 5.2 MB/s eta 0:00:00\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in d:\\anaconda\\lib\\site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.5.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB 5.3 MB/s eta 0:00:00\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53835 sha256=4c45f96746bd66ddef1aabcbc2f21f780ee4bf5073a41f153a13beb7ff93be76\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\c4\\41\\b6\\f76a356f0791da799545c23894ceae842eeff054d0eb1fb626\n",
      "Successfully built pypika\n",
      "Installing collected packages: pyreadline3, pypika, monotonic, mmh3, websockets, tqdm, shellingham, python-dotenv, pyproject_hooks, pygments, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mdurl, importlib-resources, importlib-metadata, humanfriendly, httptools, fsspec, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, markdown-it-py, huggingface-hub, coloredlogs, build, tokenizers, rich, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, typer, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.11.3\n",
      "    Uninstalling importlib-metadata-4.11.3:\n",
      "      Successfully uninstalled importlib-metadata-4.11.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.11.0\n",
      "    Uninstalling fsspec-2022.11.0:\n",
      "      Successfully uninstalled fsspec-2022.11.0\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.11.4\n",
      "    Uninstalling tokenizers-0.11.4:\n",
      "      Successfully uninstalled tokenizers-0.11.4\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.2 fsspec-2024.3.1 httptools-0.6.1 huggingface-hub-0.22.2 humanfriendly-10.0 importlib-metadata-7.0.0 importlib-resources-6.4.0 kubernetes-29.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pygments-2.17.2 pypika-0.48.9 pyproject_hooks-1.0.0 pyreadline3-3.4.1 python-dotenv-1.0.1 rich-13.7.1 shellingham-1.5.4 starlette-0.37.2 tokenizers-0.19.1 tqdm-4.66.2 typer-0.12.3 uvicorn-0.29.0 watchfiles-0.21.0 websockets-12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.24.0 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.19.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4296c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66272521",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = PyPDFLoader(r'C:\\Users\\Asus\\Downloads\\2404.07143.pdf')\n",
    "pages=content.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2d94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 568, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "text_splitter = NLTKTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "chunks=text_splitter.split_documents(pages)\n",
    "print(len(chunks))\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541825ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Preprint.\\n\\nUnder review.\\n\\nLeave No Context Behind:\\nEfficient Infinite Context Transformers with Infini-attention\\nTsendsuren Munkhdalai, Manaal Faruqui and Siddharth Gopal\\nGoogle\\ntsendsuren@google.com\\nAbstract\\nThis work introduces an efficient method to scale Transformer-based Large\\nLanguage Models (LLMs) to infinitely long inputs with bounded memory\\nand computation.\\n\\nA key component in our proposed approach is a new at-\\ntention technique dubbed Infini-attention.', metadata={'source': 'C:\\\\Users\\\\Asus\\\\Downloads\\\\2404.07143.pdf', 'page': 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "411e4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('googleapi.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a008a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Google_api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99b47c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=Google_api_key, model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e10bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=r\"C:\\Users\\Asus\\leave\\chroma_db_\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ec7068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e8bf1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32dde484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7108c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # System Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a Helpful AI Bot. \n",
    "    Your task is to provide assistance based on the context given by the user. \n",
    "    Make sure your answers are relevant and helpful.\"\"\"),\n",
    "    # Human Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05439695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=Google_api_key, model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a11d905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50b08eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6464ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87fe612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Memory Retrieval and Update in the Context of Efficient Attention Mechanisms:\\n\\nThe provided text discusses approaches to improve the efficiency of attention mechanisms in handling long sequences, focusing on memory retrieval and update processes. Let's break down the key points:\\n\\n**Challenges with Standard Attention:**\\n\\n* **Growing Memory Consumption:** Standard attention mechanisms require storing key and value (KV) pairs for each element in the input sequence. This leads to increased memory usage as the sequence length grows, making it impractical for long sequences.\\n\\n**Solutions - Compressive Memory and Retrieval:**\\n\\n* **Compressive Memory:** Instead of storing all KV pairs, a compressive memory approach maintains a fixed number of parameters. It efficiently stores information by updating these parameters in a way that allows for later retrieval. \\n* **Retrieval Mechanisms:** When processing new sequences, the attention query interacts with the compressed memory to retrieve relevant information. This information is then used to compute attention scores and update the model's representation.\\n\\n**Specific Techniques Mentioned:**\\n\\n* **Katharopoulos et al. (2020):** The text highlights the adoption of an update rule and retrieval mechanism proposed by Katharopoulos et al. due to its simplicity and effectiveness. \\n* **Infini-attention:** This approach reuses key, value, and query states from standard attention computations for long-term memory consolidation. Instead of discarding old KV states, they are stored in the compressive memory and retrieved later using attention query states when processing subsequent sequences.\\n\\n**Benefits:**\\n\\n* **Bounded Storage and Computation:** By using a fixed-size memory, compressive memory approaches avoid the memory limitations of standard attention, enabling efficient processing of long sequences.\\n* **Efficient Retrieval:** Retrieval mechanisms allow relevant information to be accessed quickly and incorporated into the model's representation, contributing to better performance. \\n\\n**Additional Considerations:**\\n\\n* **System-level Optimizations:** The text mentions exploring hardware-specific optimizations to further improve the efficiency of attention computations.\\n\\n**In summary, memory retrieval and update techniques play a crucial role in enhancing the efficiency and effectiveness of attention mechanisms for handling long sequences. By employing compressive memory and efficient retrieval methods, models can maintain performance while managing memory constraints.** \\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Can you please tell me about meory retival and memory update\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9696e9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Memory Retrieval and Update in the Context of Efficient Attention Mechanisms:\n",
       "\n",
       "The provided text discusses approaches to improve the efficiency of attention mechanisms in handling long sequences, focusing on memory retrieval and update processes. Let's break down the key points:\n",
       "\n",
       "**Challenges with Standard Attention:**\n",
       "\n",
       "* **Growing Memory Consumption:** Standard attention mechanisms require storing key and value (KV) pairs for each element in the input sequence. This leads to increased memory usage as the sequence length grows, making it impractical for long sequences.\n",
       "\n",
       "**Solutions - Compressive Memory and Retrieval:**\n",
       "\n",
       "* **Compressive Memory:** Instead of storing all KV pairs, a compressive memory approach maintains a fixed number of parameters. It efficiently stores information by updating these parameters in a way that allows for later retrieval. \n",
       "* **Retrieval Mechanisms:** When processing new sequences, the attention query interacts with the compressed memory to retrieve relevant information. This information is then used to compute attention scores and update the model's representation.\n",
       "\n",
       "**Specific Techniques Mentioned:**\n",
       "\n",
       "* **Katharopoulos et al. (2020):** The text highlights the adoption of an update rule and retrieval mechanism proposed by Katharopoulos et al. due to its simplicity and effectiveness. \n",
       "* **Infini-attention:** This approach reuses key, value, and query states from standard attention computations for long-term memory consolidation. Instead of discarding old KV states, they are stored in the compressive memory and retrieved later using attention query states when processing subsequent sequences.\n",
       "\n",
       "**Benefits:**\n",
       "\n",
       "* **Bounded Storage and Computation:** By using a fixed-size memory, compressive memory approaches avoid the memory limitations of standard attention, enabling efficient processing of long sequences.\n",
       "* **Efficient Retrieval:** Retrieval mechanisms allow relevant information to be accessed quickly and incorporated into the model's representation, contributing to better performance. \n",
       "\n",
       "**Additional Considerations:**\n",
       "\n",
       "* **System-level Optimizations:** The text mentions exploring hardware-specific optimizations to further improve the efficiency of attention computations.\n",
       "\n",
       "**In summary, memory retrieval and update techniques play a crucial role in enhancing the efficiency and effectiveness of attention mechanisms for handling long sequences. By employing compressive memory and efficient retrieval methods, models can maintain performance while managing memory constraints.** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
